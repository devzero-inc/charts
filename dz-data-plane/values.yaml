nodeLabeler:
  enabled: true

vault:
  approle:
    secretId: ""

cedana-helm:
  daemonHelper:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: sysbox-install
                  operator: In
                  values:
                    - "yes"
    image:
      repository: docker.io/cedana/cedana-helper
      tag: v0.9.229
      imagePullPolicy: IfNotPresent

    updateStrategy:
      maxSurge: 0
      maxUnavailable: 1

  controllerManager:
    manager:
      image:
        repository: docker.io/cedana/cedana-controller
        tag: v0.2.6
        imagePullPolicy: IfNotPresent

  cedanaConfig:
    cedanaUrl: https://devzero.cedana.ai
    signozAccessToken: ""
    cedanaAuthToken: ""

kube-prometheus-stack:
  prometheus:
    prometheusSpec:
      additionalScrapeConfigs:
        - job_name: "cortex"
          metrics_path: "/metrics"
          kubernetes_sd_configs:
            - role: "pod"
      podMonitorSelectorNilUsesHelmValues: false
      serviceMonitorSelectorNilUsesHelmValues: false
      ruleSelectorNilUsesHelmValues: false
      remoteWrite:
        - url: "https://mimir.devzero.dev/api/v1/push"
          headers:
            X-Scope-OrgID: "1"
          writeRelabelConfigs:
            - targetLabel: "region"
              replacement: "self-hosted"

rook-ceph:
  enabled: true
  image:
    repository: docker.io/rook/ceph
  nodeSelector:
    node-role.kubernetes.io/rook-node: "1"

  tolerations:
    - key: "rookNode"
      operator: "Exists"
      effect: "NoSchedule"

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: "node-role.kubernetes.io/rook-node"
                operator: "Exists"

  csi:
    provisionerTolerations:
      - key: "rookNode"
        operator: "Exists"
        effect: "NoSchedule"

    provisionerNodeAffinity: node-role.kubernetes.io/rook-node;

#rook-ceph-cluster:
#  operatorNamespace: "dsh"
#
#  toolbox:
#    enabled: true
#    tolerations:
#      - key: "rookNode"
#        operator: "Exists"
#        effect: "NoSchedule"
#
#    affinity:
#      nodeAffinity:
#        requiredDuringSchedulingIgnoredDuringExecution:
#          nodeSelectorTerms:
#            - matchExpressions:
#                - key: "node-role.kubernetes.io/rook-node"
#                  operator: "Exists"
#
#  cephClusterSpec:
#    annotations:
#      mgr:
#        prometheus.io/port: "9283"
#        prometheus.io/scrape: "true"
#      exporter:
#        prometheus.io/port: "9926"
#        prometheus.io/scrape: "true"
#    cephVersion:
#      image: quay.io/ceph/ceph:v18.2.4
#      allowUnsupported: false
#    mon:
#      count: 3
#      allowMultiplePerNode: false
#      volumeClaimTemplate:
#        spec:
#          storageClassName: standard-rwo
#          resources:
#            requests:
#              storage: "40Gi"
#    mgr:
#      count: 2
#      allowMultiplePerNode: false
#      modules:
#        - name: rook
#          enabled: true
#    dashboard:
#      enabled: true
#      ssl: true
#    placement:
#      all:
#        tolerations:
#          - key: "rookNode"
#            operator: "Exists"
#            effect: "NoSchedule"
#        nodeAffinity:
#          requiredDuringSchedulingIgnoredDuringExecution:
#            nodeSelectorTerms:
#              - matchExpressions:
#                  - key: node-role.kubernetes.io/rook-node
#                    operator: In
#                    values:
#                      - "1"
#    storage:
#      useAllNodes: false
#      useAllDevices: false
#      storageClassDeviceSets:
#        - name: set1
#          count: 3
#          portable: true
#          tuneDeviceClass: true
#          placement:
#            topologySpreadConstraints:
#              - maxSkew: 1
#                topologyKey: kubernetes.io/hostname
#                whenUnsatisfiable: ScheduleAnyway
#                labelSelector:
#                  matchExpressions:
#                    - key: app
#                      operator: In
#                      values:
#                        - rook-ceph-osd
#          preparePlacement:
#            podAntiAffinity:
#              preferredDuringSchedulingIgnoredDuringExecution:
#                - weight: 100
#                  podAffinityTerm:
#                    labelSelector:
#                      matchExpressions:
#                        - key: app
#                          operator: In
#                          values:
#                            - rook-ceph-osd
#                        - key: app
#                          operator: In
#                          values:
#                            - rook-ceph-osd-prepare
#                    topologyKey: kubernetes.io/hostname
#            topologySpreadConstraints:
#              - maxSkew: 1
#                topologyKey: topology.kubernetes.io/zone
#                whenUnsatisfiable: DoNotSchedule
#                labelSelector:
#                  matchExpressions:
#                    - key: app
#                      operator: In
#                      values:
#                        - rook-ceph-osd-prepare
#          volumeClaimTemplates:
#            - metadata:
#                name: data
#              spec:
#                resources:
#                  requests:
#                    storage: "1Ti"
#                storageClassName: premium-rwo
#                volumeMode: Block
#                accessModes:
#                  - ReadWriteOnce
#
#  cephBlockPools:
#    - name: ceph-blockpool
#      # see https://github.com/rook/rook/blob/master/Documentation/CRDs/Block-Storage/ceph-block-pool-crd.md#spec for available configuration
#      spec:
#        failureDomain: host
#        replicated:
#          size: 3
#      storageClass:
#        enabled: true
#        name: ceph-block
#        annotations: { }
#        labels: { }
#        isDefault: false
#        reclaimPolicy: Delete
#        allowVolumeExpansion: true
#        volumeBindingMode: "Immediate"
#        mountOptions: [ ]
#        allowedTopologies: [ ]
#        parameters:
#          imageFormat: "2"
#          imageFeatures: layering
#          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
#          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
#          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
#          csi.storage.k8s.io/fstype: ext4
#
#  cephFileSystems:
#    - name: ceph-filesystem
#      spec:
#        metadataPool:
#          replicated:
#            size: 3
#        dataPools:
#          - failureDomain: host
#            replicated:
#              size: 3
#            name: data0
#        metadataServer:
#          activeCount: 1
#          activeStandby: true
#          resources:
#            limits:
#              memory: "4Gi"
#            requests:
#              cpu: "1000m"
#              memory: "4Gi"
#          placement:
#            tolerations:
#              - key: "rookNode"
#                operator: "Exists"
#                effect: "NoSchedule"
#            nodeAffinity:
#              requiredDuringSchedulingIgnoredDuringExecution:
#                nodeSelectorTerms:
#                  - matchExpressions:
#                      - key: node-role.kubernetes.io/rook-node
#                        operator: In
#                        values:
#                          - "1"
#      storageClass:
#        enabled: true
#        isDefault: false
#        name: ceph-filesystem
#        pool: data0
#        reclaimPolicy: Delete
#        allowVolumeExpansion: true
#        volumeBindingMode: "Immediate"
#        annotations: { }
#        labels: { }
#        mountOptions: [ ]
#        parameters:
#          csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
#          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
#          csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
#          csi.storage.k8s.io/fstype: ext4
#
#  cephFileSystemVolumeSnapshotClass:
#    enabled: false
#    name: ceph-filesystem
#    isDefault: false
#    deletionPolicy: Delete
#    annotations: { }
#    labels: { }
#    parameters: { }
#
#  cephBlockPoolsVolumeSnapshotClass:
#    enabled: false
#    name: ceph-block
#    isDefault: false
#    deletionPolicy: Delete
#    annotations: { }
#    labels: { }
#    parameters: { }
#
#  cephObjectStores:
#    - name: ceph-objectstore
#      spec:
#        metadataPool:
#          failureDomain: host
#          replicated:
#            size: 3
#        dataPool:
#          failureDomain: host
#          erasureCoded:
#            dataChunks: 2
#            codingChunks: 1
#        preservePoolsOnDelete: true
#        gateway:
#          port: 80
#          resources:
#            limits:
#              memory: "2Gi"
#            requests:
#              cpu: "1000m"
#              memory: "1Gi"
#          instances: 1
#          placement:
#            tolerations:
#              - key: "rookNode"
#                operator: "Exists"
#                effect: "NoSchedule"
#            nodeAffinity:
#              requiredDuringSchedulingIgnoredDuringExecution:
#                nodeSelectorTerms:
#                  - matchExpressions:
#                      - key: node-role.kubernetes.io/rook-node
#                        operator: In
#                        values:
#                          - "1"
#        allowUsersInNamespaces:
#          - "rook-ceph"
#          - "shared-storage"
#        hosting:
#          advertiseEndpoint:
#            dnsName: rook-ceph-rgw-ceph-objectstore.rook-ceph.svc
#          dnsNames:
#            - rook-ceph-rgw-ceph-objectstore.rook-ceph.svc
#            - object-store.devzero.svc
#            - localhost
#      storageClass:
#        enabled: true
#        name: ceph-bucket
#        reclaimPolicy: Delete
#        volumeBindingMode: "Immediate"
#        annotations: { }
#        labels: { }
#        parameters:
#          region: us-east-1
#      ingress:
#        enabled: false
